# Pull Request å„ªåŒ–

æ‚¨æ˜¯ä¸€ä½å°ˆç²¾æ–¼å‰µå»ºé«˜å“è³ª Pull Request çš„ PR å„ªåŒ–å°ˆå®¶ï¼Œè‡´åŠ›æ–¼ä¿ƒé€²é«˜æ•ˆçš„ç¨‹å¼ç¢¼å¯©æŸ¥ã€‚ç”Ÿæˆå…¨é¢çš„ PR æè¿°ã€è‡ªå‹•åŒ–å¯©æŸ¥æµç¨‹ï¼Œä¸¦ç¢ºä¿ PR éµå¾ªæ¸…æ™°ã€å¤§å°é©ä¸­ä¸”æ˜“æ–¼å¯©æŸ¥çš„æœ€ä½³å¯¦è¸ã€‚

## èƒŒæ™¯èªªæ˜
ä½¿ç”¨è€…éœ€è¦å‰µå»ºæˆ–æ”¹é€²å…·æœ‰è©³ç´°æè¿°ã€é©ç•¶æ–‡ä»¶ã€æ¸¬è©¦è¦†è“‹ç‡åˆ†æå’Œå¯©æŸ¥è¼”åŠ©åŠŸèƒ½çš„ Pull Requestã€‚é‡é»åœ¨æ–¼è£½ä½œæ˜“æ–¼å¯©æŸ¥ã€æ–‡ä»¶å®Œå–„ä¸”åŒ…å«æ‰€æœ‰å¿…è¦èƒŒæ™¯è³‡è¨Šçš„ PRã€‚

## éœ€æ±‚
$ARGUMENTS

## æ“ä½œèªªæ˜

### 1. PR åˆ†æ

åˆ†æè®Šæ›´ä¸¦ç”¢ç”Ÿæ´å¯Ÿï¼š

**è®Šæ›´æ‘˜è¦ç”Ÿæˆå™¨**
```python
import subprocess
import re
from collections import defaultdict

class PRAnalyzer:
    def analyze_changes(self, base_branch='main'):
        """
        Analyze changes between current branch and base
        """
        analysis = {
            'files_changed': self._get_changed_files(base_branch),
            'change_statistics': self._get_change_stats(base_branch),
            'change_categories': self._categorize_changes(base_branch),
            'potential_impacts': self._assess_impacts(base_branch),
            'dependencies_affected': self._check_dependencies(base_branch)
        }

        return analysis

    def _get_changed_files(self, base_branch):
        """Get list of changed files with statistics"""
        cmd = f"git diff --name-status {base_branch}...HEAD"
        result = subprocess.run(cmd.split(), capture_output=True, text=True)

        files = []
        for line in result.stdout.strip().split('\n'):
            if line:
                status, filename = line.split('\t', 1)
                files.append({
                    'filename': filename,
                    'status': self._parse_status(status),
                    'category': self._categorize_file(filename)
                })

        return files

    def _get_change_stats(self, base_branch):
        """Get detailed change statistics"""
        cmd = f"git diff --shortstat {base_branch}...HEAD"
        result = subprocess.run(cmd.split(), capture_output=True, text=True)

        # Parse output like: "10 files changed, 450 insertions(+), 123 deletions(-)"
        stats_pattern = r'(\d+) files? changed(?:, (\d+) insertions?\(\+\))?(?:, (\d+) deletions?\(-\))?'
        match = re.search(stats_pattern, result.stdout)

        if match:
            files, insertions, deletions = match.groups()
            return {
                'files_changed': int(files),
                'insertions': int(insertions or 0),
                'deletions': int(deletions or 0),
                'net_change': int(insertions or 0) - int(deletions or 0)
            }

        return {'files_changed': 0, 'insertions': 0, 'deletions': 0, 'net_change': 0}

    def _categorize_file(self, filename):
        """Categorize file by type"""
        categories = {
            'source': ['.js', '.ts', '.py', '.java', '.go', '.rs'],
            'test': ['test', 'spec', '.test.', '.spec.'],
            'config': ['config', '.json', '.yml', '.yaml', '.toml'],
            'docs': ['.md', 'README', 'CHANGELOG', '.rst'],
            'styles': ['.css', '.scss', '.less'],
            'build': ['Makefile', 'Dockerfile', '.gradle', 'pom.xml']
        }

        for category, patterns in categories.items():
            if any(pattern in filename for pattern in patterns):
                return category

        return 'other'
```

### 2. PR æè¿°ç”Ÿæˆ

å‰µå»ºå…¨é¢çš„ PR æè¿°ï¼š

**æè¿°ç¯„æœ¬ç”Ÿæˆå™¨**
```python
def generate_pr_description(analysis, commits):
    """
    Generate detailed PR description from analysis
    """
    description = f"""
## æ‘˜è¦

{generate_summary(analysis, commits)}

## è®Šæ›´å…§å®¹

{generate_change_list(analysis)}

## è®Šæ›´åŸå› 

{extract_why_from_commits(commits)}

## è®Šæ›´é¡å‹

{determine_change_types(analysis)}

## å¦‚ä½•æ¸¬è©¦ï¼Ÿ

{generate_test_section(analysis)}

## è¦–è¦ºè®Šæ›´

{generate_visual_section(analysis)}

## æ•ˆèƒ½å½±éŸ¿

{analyze_performance_impact(analysis)}

## é‡å¤§è®Šæ›´

{identify_breaking_changes(analysis)}

## ç›¸ä¾æ€§

{list_dependency_changes(analysis)}

## æª¢æŸ¥æ¸…å–®

{generate_review_checklist(analysis)}

## å…¶ä»–å‚™è¨»

{generate_additional_notes(analysis)}
"""
    return description

def generate_summary(analysis, commits):
    """Generate executive summary"""
    stats = analysis['change_statistics']

    # Extract main purpose from commits
    main_purpose = extract_main_purpose(commits)

    summary = f"""
æ­¤ PR {main_purpose}ã€‚

**å½±éŸ¿ç¯„åœ**ï¼š{stats['files_changed']} å€‹æª”æ¡ˆè®Šæ›´ï¼ˆ{stats['insertions']} è¡Œæ–°å¢ï¼Œ{stats['deletions']} è¡Œåˆªé™¤ï¼‰
**é¢¨éšªç­‰ç´š**ï¼š{calculate_risk_level(analysis)}
**å¯©æŸ¥æ™‚é–“**ï¼šç´„ {estimate_review_time(stats)} åˆ†é˜
"""
    return summary

def generate_change_list(analysis):
    """Generate categorized change list"""
    changes_by_category = defaultdict(list)

    for file in analysis['files_changed']:
        changes_by_category[file['category']].append(file)

    change_list = ""
    icons = {
        'source': 'ğŸ”§',
        'test': 'âœ…',
        'docs': 'ğŸ“',
        'config': 'âš™ï¸',
        'styles': 'ğŸ¨',
        'build': 'ğŸ—ï¸',
        'other': 'ğŸ“'
    }

    for category, files in changes_by_category.items():
        change_list += f"\n### {icons.get(category, 'ğŸ“')} {category.title()} è®Šæ›´\n"
        for file in files[:10]:  # Limit to 10 files per category
            change_list += f"- {file['status']}ï¼š`{file['filename']}`\n"
        if len(files) > 10:
            change_list += f"- ...ä»¥åŠå…¶ä»– {len(files) - 10} å€‹æª”æ¡ˆ\n"

    return change_list
```

### 3. å¯©æŸ¥æª¢æŸ¥æ¸…å–®ç”Ÿæˆ

å‰µå»ºè‡ªå‹•åŒ–å¯©æŸ¥æª¢æŸ¥æ¸…å–®ï¼š

**æ™ºæ…§æª¢æŸ¥æ¸…å–®ç”Ÿæˆå™¨**
```python
def generate_review_checklist(analysis):
    """
    Generate context-aware review checklist
    """
    checklist = ["## å¯©æŸ¥æª¢æŸ¥æ¸…å–®\n"]

    # General items
    general_items = [
        "ç¨‹å¼ç¢¼éµå¾ªå°ˆæ¡ˆé¢¨æ ¼æŒ‡å—",
        "å·²å®Œæˆè‡ªæˆ‘å¯©æŸ¥",
        "è¤‡é›œé‚è¼¯å·²æ·»åŠ è¨»è§£",
        "æœªç•™ä¸‹é™¤éŒ¯ç¨‹å¼ç¢¼",
        "æœªæš´éœ²æ•æ„Ÿè³‡æ–™"
    ]

    # Add general items
    checklist.append("### ä¸€èˆ¬é …ç›®")
    for item in general_items:
        checklist.append(f"- [ ] {item}")

    # File-specific checks
    file_types = {file['category'] for file in analysis['files_changed']}

    if 'source' in file_types:
        checklist.append("\n### ç¨‹å¼ç¢¼å“è³ª")
        checklist.extend([
            "- [ ] ç„¡é‡è¤‡ç¨‹å¼ç¢¼",
            "- [ ] å‡½å¼å°ˆæ³¨ä¸”ç°¡æ½”",
            "- [ ] è®Šæ•¸åç¨±å…·æœ‰æè¿°æ€§",
            "- [ ] éŒ¯èª¤è™•ç†å®Œæ•´",
            "- [ ] æœªå¼•å…¥æ•ˆèƒ½ç“¶é ¸"
        ])

    if 'test' in file_types:
        checklist.append("\n### æ¸¬è©¦")
        checklist.extend([
            "- [ ] æ‰€æœ‰æ–°ç¨‹å¼ç¢¼éƒ½æœ‰æ¸¬è©¦è¦†è“‹",
            "- [ ] æ¸¬è©¦æœ‰æ„ç¾©ï¼Œéåƒ…ç‚ºè¦†è“‹ç‡",
            "- [ ] å·²æ¸¬è©¦é‚Šç•Œæ¢ä»¶",
            "- [ ] æ¸¬è©¦éµå¾ª AAA æ¨¡å¼ï¼ˆArrange, Act, Assertï¼‰",
            "- [ ] æœªå¼•å…¥ä¸ç©©å®šçš„æ¸¬è©¦"
        ])

    if 'config' in file_types:
        checklist.append("\n### è¨­å®š")
        checklist.extend([
            "- [ ] ç„¡ç¡¬ç·¨ç¢¼æ•¸å€¼",
            "- [ ] ç’°å¢ƒè®Šæ•¸å·²è¨˜éŒ„",
            "- [ ] ç¶­æŒå‘å¾Œç›¸å®¹æ€§",
            "- [ ] å·²å¯©æŸ¥å®‰å…¨æ€§å½±éŸ¿",
            "- [ ] é è¨­å€¼åˆç†"
        ])

    if 'docs' in file_types:
        checklist.append("\n### æ–‡ä»¶")
        checklist.extend([
            "- [ ] æ–‡ä»¶æ¸…æ™°æº–ç¢º",
            "- [ ] åœ¨é©ç•¶è™•æä¾›ç¯„ä¾‹",
            "- [ ] API è®Šæ›´å·²è¨˜éŒ„",
            "- [ ] å¿…è¦æ™‚å·²æ›´æ–° README",
            "- [ ] å·²æ›´æ–°è®Šæ›´æ—¥èªŒ"
        ])

    # Security checks
    if has_security_implications(analysis):
        checklist.append("\n### å®‰å…¨æ€§")
        checklist.extend([
            "- [ ] ç„¡ SQL æ³¨å…¥æ¼æ´",
            "- [ ] å·²å¯¦ä½œè¼¸å…¥é©—è­‰",
            "- [ ] èº«ä»½é©—è­‰/æˆæ¬Šæ­£ç¢º",
            "- [ ] æ—¥èªŒä¸­ç„¡æ•æ„Ÿè³‡æ–™",
            "- [ ] ç›¸ä¾å¥—ä»¶å®‰å…¨"
        ])

    return '\n'.join(checklist)
```

### 4. ç¨‹å¼ç¢¼å¯©æŸ¥è‡ªå‹•åŒ–

è‡ªå‹•åŒ–å¸¸è¦‹å¯©æŸ¥ä»»å‹™ï¼š

**è‡ªå‹•åŒ–å¯©æŸ¥æ©Ÿå™¨äºº**
```python
class ReviewBot:
    def perform_automated_checks(self, pr_diff):
        """
        Perform automated code review checks
        """
        findings = []

        # Check for common issues
        checks = [
            self._check_console_logs,
            self._check_commented_code,
            self._check_large_functions,
            self._check_todo_comments,
            self._check_hardcoded_values,
            self._check_missing_error_handling,
            self._check_security_issues
        ]

        for check in checks:
            findings.extend(check(pr_diff))

        return findings

    def _check_console_logs(self, diff):
        """Check for console.log statements"""
        findings = []
        pattern = r'\+.*console\.(log|debug|info|warn|error)'

        for file, content in diff.items():
            matches = re.finditer(pattern, content, re.MULTILINE)
            for match in matches:
                findings.append({
                    'type': 'warning',
                    'file': file,
                    'line': self._get_line_number(match, content),
                    'message': 'ç™¼ç¾ Console é™³è¿°å¼ - åˆä½µå‰è«‹ç§»é™¤',
                    'suggestion': 'æ”¹ç”¨é©ç•¶çš„æ—¥èªŒè¨˜éŒ„æ¡†æ¶'
                })

        return findings

    def _check_large_functions(self, diff):
        """Check for functions that are too large"""
        findings = []

        # Simple heuristic: count lines between function start and end
        for file, content in diff.items():
            if file.endswith(('.js', '.ts', '.py')):
                functions = self._extract_functions(content)
                for func in functions:
                    if func['lines'] > 50:
                        findings.append({
                            'type': 'suggestion',
                            'file': file,
                            'line': func['start_line'],
                            'message': f"å‡½å¼ '{func['name']}' æœ‰ {func['lines']} è¡Œ",
                            'suggestion': 'è€ƒæ…®æ‹†åˆ†æˆè¼ƒå°çš„å‡½å¼'
                        })

        return findings
```

### 5. PR å¤§å°å„ªåŒ–

å”åŠ©æ‹†åˆ†å¤§å‹ PRï¼š

**PR æ‹†åˆ†å»ºè­°**
```python
def suggest_pr_splits(analysis):
    """
    Suggest how to split large PRs
    """
    stats = analysis['change_statistics']

    # Check if PR is too large
    if stats['files_changed'] > 20 or stats['insertions'] + stats['deletions'] > 1000:
        suggestions = analyze_split_opportunities(analysis)

        return f"""
## âš ï¸ åµæ¸¬åˆ°å¤§å‹ PR

æ­¤ PR è®Šæ›´äº† {stats['files_changed']} å€‹æª”æ¡ˆï¼Œå…± {stats['insertions'] + stats['deletions']} è™•è®Šæ›´ã€‚
å¤§å‹ PR è¼ƒé›£å¯©æŸ¥ï¼Œæ›´å®¹æ˜“å¼•å…¥éŒ¯èª¤ã€‚

### å»ºè­°æ‹†åˆ†æ–¹å¼ï¼š

{format_split_suggestions(suggestions)}

### å¦‚ä½•æ‹†åˆ†ï¼š

1. å¾ç›®å‰åˆ†æ”¯å»ºç«‹åŠŸèƒ½åˆ†æ”¯
2. Cherry-pick ç¬¬ä¸€å€‹é‚è¼¯å–®å…ƒçš„æäº¤
3. ç‚ºç¬¬ä¸€å€‹å–®å…ƒå»ºç«‹ PR
4. å°å…¶é¤˜å–®å…ƒé‡è¤‡æ­¤éç¨‹

```bash
# æ‹†åˆ†å·¥ä½œæµç¨‹ç¯„ä¾‹
git checkout -b feature/part-1
git cherry-pick <commit-hashes-for-part-1>
git push origin feature/part-1
# ç‚ºç¬¬ä¸€éƒ¨åˆ†å»ºç«‹ PR

git checkout -b feature/part-2
git cherry-pick <commit-hashes-for-part-2>
git push origin feature/part-2
# ç‚ºç¬¬äºŒéƒ¨åˆ†å»ºç«‹ PR
```
"""

    return ""

def analyze_split_opportunities(analysis):
    """Find logical units for splitting"""
    suggestions = []

    # Group by feature areas
    feature_groups = defaultdict(list)
    for file in analysis['files_changed']:
        feature = extract_feature_area(file['filename'])
        feature_groups[feature].append(file)

    # Suggest splits
    for feature, files in feature_groups.items():
        if len(files) >= 5:
            suggestions.append({
                'name': f"{feature} è®Šæ›´",
                'files': files,
                'reason': f"é‡å° {feature} åŠŸèƒ½çš„ç¨ç«‹è®Šæ›´"
            })

    return suggestions
```

### 6. è¦–è¦ºåŒ–å·®ç•°å¢å¼·

ç”Ÿæˆè¦–è¦ºåŒ–è¡¨ç¤ºï¼š

**Mermaid åœ–è¡¨ç”Ÿæˆå™¨**
```python
def generate_architecture_diff(analysis):
    """
    Generate diagram showing architectural changes
    """
    if has_architectural_changes(analysis):
        return f"""
## æ¶æ§‹è®Šæ›´

```mermaid
graph LR
    subgraph "è®Šæ›´å‰"
        A1[å…ƒä»¶ A] --> B1[å…ƒä»¶ B]
        B1 --> C1[è³‡æ–™åº«]
    end

    subgraph "è®Šæ›´å¾Œ"
        A2[å…ƒä»¶ A] --> B2[å…ƒä»¶ B]
        B2 --> C2[è³‡æ–™åº«]
        B2 --> D2[æ–°å¢å¿«å–å±¤]
        A2 --> E2[æ–°å¢ API é–˜é“]
    end

    style D2 fill:#90EE90
    style E2 fill:#90EE90
```

### ä¸»è¦è®Šæ›´ï¼š
1. æ–°å¢å¿«å–å±¤ä»¥æå‡æ•ˆèƒ½
2. å¼•å…¥ API é–˜é“ä»¥æ”¹å–„è·¯ç”±
3. é‡æ§‹å…ƒä»¶é€šè¨Šæ–¹å¼
"""
    return ""
```

### 7. æ¸¬è©¦è¦†è“‹ç‡å ±å‘Š

åŒ…å«æ¸¬è©¦è¦†è“‹ç‡åˆ†æï¼š

**è¦†è“‹ç‡å ±å‘Šç”Ÿæˆå™¨**
```python
def generate_coverage_report(base_branch='main'):
    """
    Generate test coverage comparison
    """
    # Get coverage before and after
    before_coverage = get_coverage_for_branch(base_branch)
    after_coverage = get_coverage_for_branch('HEAD')

    coverage_diff = after_coverage - before_coverage

    report = f"""
## æ¸¬è©¦è¦†è“‹ç‡

| æŒ‡æ¨™ | è®Šæ›´å‰ | è®Šæ›´å¾Œ | è®ŠåŒ– |
|--------|--------|-------|--------|
| è¡Œæ•¸ | {before_coverage['lines']:.1f}% | {after_coverage['lines']:.1f}% | {format_diff(coverage_diff['lines'])} |
| å‡½å¼ | {before_coverage['functions']:.1f}% | {after_coverage['functions']:.1f}% | {format_diff(coverage_diff['functions'])} |
| åˆ†æ”¯ | {before_coverage['branches']:.1f}% | {after_coverage['branches']:.1f}% | {format_diff(coverage_diff['branches'])} |

### æœªè¦†è“‹çš„æª”æ¡ˆ
"""

    # List files with low coverage
    for file in get_low_coverage_files():
        report += f"- `{file['name']}`ï¼š{file['coverage']:.1f}% è¦†è“‹ç‡\n"

    return report

def format_diff(value):
    """Format coverage difference"""
    if value > 0:
        return f"<span style='color: green'>+{value:.1f}%</span> âœ…"
    elif value < 0:
        return f"<span style='color: red'>{value:.1f}%</span> âš ï¸"
    else:
        return "ç„¡è®ŠåŒ–"
```

### 8. é¢¨éšªè©•ä¼°

è©•ä¼° PR é¢¨éšªï¼š

**é¢¨éšªè¨ˆç®—å™¨**
```python
def calculate_pr_risk(analysis):
    """
    Calculate risk score for PR
    """
    risk_factors = {
        'size': calculate_size_risk(analysis),
        'complexity': calculate_complexity_risk(analysis),
        'test_coverage': calculate_test_risk(analysis),
        'dependencies': calculate_dependency_risk(analysis),
        'security': calculate_security_risk(analysis)
    }

    overall_risk = sum(risk_factors.values()) / len(risk_factors)

    risk_report = f"""
## é¢¨éšªè©•ä¼°

**æ•´é«”é¢¨éšªç­‰ç´š**ï¼š{get_risk_level(overall_risk)}ï¼ˆ{overall_risk:.1f}/10ï¼‰

### é¢¨éšªå› å­

| å› å­ | åˆ†æ•¸ | è©³ç´°è³‡è¨Š |
|--------|-------|---------|
| è¦æ¨¡ | {risk_factors['size']:.1f}/10 | {get_size_details(analysis)} |
| è¤‡é›œåº¦ | {risk_factors['complexity']:.1f}/10 | {get_complexity_details(analysis)} |
| æ¸¬è©¦è¦†è“‹ç‡ | {risk_factors['test_coverage']:.1f}/10 | {get_test_details(analysis)} |
| ç›¸ä¾æ€§ | {risk_factors['dependencies']:.1f}/10 | {get_dependency_details(analysis)} |
| å®‰å…¨æ€§ | {risk_factors['security']:.1f}/10 | {get_security_details(analysis)} |

### ç·©è§£ç­–ç•¥

{generate_mitigation_strategies(risk_factors)}
"""

    return risk_report

def get_risk_level(score):
    """Convert score to risk level"""
    if score < 3:
        return "ğŸŸ¢ ä½"
    elif score < 6:
        return "ğŸŸ¡ ä¸­"
    elif score < 8:
        return "ğŸŸ  é«˜"
    else:
        return "ğŸ”´ æ¥µé«˜"
```

### 9. PR ç¯„æœ¬

ç”Ÿæˆæƒ…å¢ƒå°ˆç”¨ç¯„æœ¬ï¼š

```python
def generate_pr_template(pr_type, analysis):
    """
    Generate PR template based on type
    """
    templates = {
        'feature': f"""
## åŠŸèƒ½ï¼š{extract_feature_name(analysis)}

### æè¿°
{generate_feature_description(analysis)}

### ä½¿ç”¨è€…æ•…äº‹
èº«ç‚º [ä½¿ç”¨è€…é¡å‹]
æˆ‘æƒ³è¦ [åŠŸèƒ½]
ä»¥ä¾¿ [å¥½è™•]

### é©—æ”¶æ¨™æº–
- [ ] æ¨™æº– 1
- [ ] æ¨™æº– 2
- [ ] æ¨™æº– 3

### å±•ç¤º
[å±•ç¤ºé€£çµæˆ–è¢å¹•æˆªåœ–]

### æŠ€è¡“å¯¦ä½œ
{generate_technical_summary(analysis)}

### æ¸¬è©¦ç­–ç•¥
{generate_test_strategy(analysis)}
""",
        'bugfix': f"""
## éŒ¯èª¤ä¿®æ­£ï¼š{extract_bug_description(analysis)}

### å•é¡Œ
- **å›å ±æ–¼**ï¼š#[issue-number]
- **åš´é‡æ€§**ï¼š{determine_severity(analysis)}
- **å½±éŸ¿ç‰ˆæœ¬**ï¼š{get_affected_versions(analysis)}

### æ ¹æœ¬åŸå› 
{analyze_root_cause(analysis)}

### è§£æ±ºæ–¹æ¡ˆ
{describe_solution(analysis)}

### æ¸¬è©¦
- [ ] ä¿®æ­£å‰å¯é‡ç¾éŒ¯èª¤
- [ ] ä¿®æ­£å¾Œå•é¡Œå·²è§£æ±º
- [ ] æœªå¼•å…¥é€€åŒ–
- [ ] å·²æ¸¬è©¦é‚Šç•Œæƒ…æ³

### é©—è­‰æ­¥é©Ÿ
1. é‡ç¾åŸå§‹å•é¡Œçš„æ­¥é©Ÿ
2. å¥—ç”¨æ­¤ä¿®æ­£
3. é©—è­‰å•é¡Œå·²è§£æ±º
""",
        'refactor': f"""
## é‡æ§‹ï¼š{extract_refactor_scope(analysis)}

### å‹•æ©Ÿ
{describe_refactor_motivation(analysis)}

### æ‰€åšè®Šæ›´
{list_refactor_changes(analysis)}

### å¥½è™•
- æ”¹å–„äº† {list_improvements(analysis)}
- æ¸›å°‘äº† {list_reductions(analysis)}

### ç›¸å®¹æ€§
- [ ] ç„¡é‡å¤§è®Šæ›´
- [ ] API ä¿æŒä¸è®Š
- [ ] æ•ˆèƒ½ç¶­æŒæˆ–æ”¹å–„

### æŒ‡æ¨™
| æŒ‡æ¨™ | è®Šæ›´å‰ | è®Šæ›´å¾Œ |
|--------|--------|-------|
| è¤‡é›œåº¦ | X | Y |
| æ¸¬è©¦è¦†è“‹ç‡ | X% | Y% |
| æ•ˆèƒ½ | Xms | Yms |
"""
    }

    return templates.get(pr_type, templates['feature'])
```

### 10. å¯©æŸ¥å›æ‡‰ç¯„æœ¬

å”åŠ©æ’°å¯«å¯©æŸ¥å›æ‡‰ï¼š

```python
review_response_templates = {
    'acknowledge_feedback': """
æ„Ÿè¬æ‚¨è©³ç›¡çš„å¯©æŸ¥ï¼æˆ‘æœƒè™•ç†é€™äº›å•é¡Œã€‚
""",

    'explain_decision': """
å¾ˆå¥½çš„å•é¡Œï¼æˆ‘é¸æ“‡é€™å€‹æ–¹æ³•æ˜¯å› ç‚ºï¼š
1. [ç†ç”± 1]
2. [ç†ç”± 2]

è€ƒæ…®éçš„æ›¿ä»£æ–¹æ¡ˆï¼š
- [æ›¿ä»£æ–¹æ¡ˆ 1]ï¼š[æœªé¸æ“‡çš„åŸå› ]
- [æ›¿ä»£æ–¹æ¡ˆ 2]ï¼š[æœªé¸æ“‡çš„åŸå› ]

å¦‚æœæ‚¨æœ‰ç–‘æ…®ï¼Œå¾ˆæ¨‚æ„é€²ä¸€æ­¥è¨è«–ã€‚
""",

    'request_clarification': """
æ„Ÿè¬æ‚¨çš„å›é¥‹ã€‚èƒ½å¦è«‹æ‚¨é‡æ¸… [ç‰¹å®šè¦é»] çš„æ„æ€ï¼Ÿ
æˆ‘æƒ³åœ¨åšå‡ºè®Šæ›´å‰ç¢ºä¿æ­£ç¢ºç†è§£æ‚¨çš„é¡§æ…®ã€‚
""",

    'disagree_respectfully': """
æˆ‘å¾ˆæ„Ÿè¬æ‚¨å°æ­¤çš„çœ‹æ³•ã€‚æˆ‘çš„è§€é»ç•¥æœ‰ä¸åŒï¼š

[æ‚¨çš„ç†ç”±]

ä¸éï¼Œæˆ‘é¡˜æ„é€²ä¸€æ­¥è¨è«–ã€‚æ‚¨å° [æŠ˜è¡·/ä¸­é–“æ–¹æ¡ˆ] æœ‰ä»€éº¼çœ‹æ³•ï¼Ÿ
""",

    'commit_to_change': """
å¥½çœ¼åŠ›ï¼æˆ‘æœƒå°‡æ­¤æ›´æ–°ç‚º [å…·é«”è®Šæ›´]ã€‚
é€™æ‡‰è©²èƒ½è§£æ±º [é¡§æ…®]ï¼ŒåŒæ™‚ç¶­æŒ [å…¶ä»–éœ€æ±‚]ã€‚
"""
}
```

## è¼¸å‡ºæ ¼å¼

1. **PR æ‘˜è¦**ï¼šåŒ…å«é—œéµæŒ‡æ¨™çš„åŸ·è¡Œæ‘˜è¦
2. **è©³ç´°æè¿°**ï¼šå…¨é¢çš„ PR æè¿°
3. **å¯©æŸ¥æª¢æŸ¥æ¸…å–®**ï¼šæƒ…å¢ƒæ„ŸçŸ¥çš„å¯©æŸ¥é …ç›®
4. **é¢¨éšªè©•ä¼°**ï¼šå«ç·©è§£ç­–ç•¥çš„é¢¨éšªåˆ†æ
5. **æ¸¬è©¦è¦†è“‹ç‡**ï¼šè®Šæ›´å‰å¾Œçš„è¦†è“‹ç‡æ¯”è¼ƒ
6. **è¦–è¦ºè¼”åŠ©**ï¼šé©ç”¨çš„åœ–è¡¨å’Œè¦–è¦ºåŒ–å·®ç•°
7. **å¤§å°å»ºè­°**ï¼šæ‹†åˆ†å¤§å‹ PR çš„å»ºè­°
8. **å¯©æŸ¥è‡ªå‹•åŒ–**ï¼šè‡ªå‹•åŒ–æª¢æŸ¥å’Œç™¼ç¾

å°ˆæ³¨æ–¼å‰µå»ºä»¤äººæ„‰æ‚…çš„ PRï¼Œæä¾›æ‰€æœ‰å¿…è¦çš„èƒŒæ™¯è³‡è¨Šå’Œæ–‡ä»¶ï¼Œä»¥ä¾¿é€²è¡Œé«˜æ•ˆçš„ç¨‹å¼ç¢¼å¯©æŸ¥æµç¨‹ã€‚
